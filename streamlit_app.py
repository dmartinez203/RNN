import json
import os
from pathlib import Path

import numpy as np
import streamlit as st
import tensorflow as tf
from tensorflow import keras

# Paths (relative to repo root)
BASE_DIR = Path(__file__).resolve().parent
ART_DIR = BASE_DIR / 'artifacts'
MODEL_DIR = BASE_DIR / 'models'

CFG_PATH = ART_DIR / 'config.json'
TOK_PATH = ART_DIR / 'tokenizer.json'
MODEL_PATH = MODEL_DIR / 'best_next_word_lstm.keras'
EVAL_PATH = ART_DIR / 'eval_metrics.json'
COST_PATH = ART_DIR / 'cost_metrics_report.json'

st.set_page_config(page_title="Next-Word LSTM Demo", page_icon="üìù", layout="centered")
st.title("Next-Word Prediction (LSTM)")

@st.cache_resource
def load_assets():
    if not CFG_PATH.exists() or not TOK_PATH.exists() or not MODEL_PATH.exists():
        raise FileNotFoundError(
            "Missing artifacts. Please run the notebook to generate 'models/best_next_word_lstm.keras' and 'artifacts/tokenizer.json'/'artifacts/config.json'."
        )
    with open(CFG_PATH, 'r') as f:
        cfg = json.load(f)
    with open(TOK_PATH, 'r') as f:
        tok_json = f.read()
    tokenizer = keras.preprocessing.text.tokenizer_from_json(tok_json)
    model = keras.models.load_model(MODEL_PATH)
    # Build reverse index
    word_index = tokenizer.word_index
    index_word = {i: w for w, i in word_index.items()}
    return cfg, tokenizer, model, index_word


def clean_text(s: str):
    import re, string
    table = str.maketrans('', '', string.punctuation)
    s = s.lower().translate(table)
    s = re.sub(r"\s+", " ", s)
    return s.strip()


def generate_next_token(model, tokenizer, index_word, cfg, seed_tokens, temperature: float = 1.0):
    seq_len = int(cfg['SEQ_LEN'])
    x = seed_tokens[-seq_len:]
    if len(x) < seq_len:
        x = [0] * (seq_len - len(x)) + x
    x = np.array([x], dtype=np.int32)
    preds = model.predict(x, verbose=0)[0]
    if temperature is None or temperature == 0.0:
        return int(np.argmax(preds))
    logits = np.log(preds + 1e-9) / max(1e-6, temperature)
    exp = np.exp(logits - np.max(logits))
    probs = exp / np.sum(exp)
    return int(np.random.choice(len(probs), p=probs))


def complete_text(model, tokenizer, index_word, cfg, prompt: str, num_words: int = 10, temperature: float = 0.8):
    s = clean_text(prompt)
    tokens = tokenizer.texts_to_sequences([s])[0]
    max_vocab = cfg.get('MAX_VOCAB')
    if max_vocab:
        tokens = [t if t <= max_vocab else tokenizer.word_index.get('[OOV]') for t in tokens]
    out_tokens = list(tokens)
    for _ in range(num_words):
        idx = generate_next_token(model, tokenizer, index_word, cfg, out_tokens, temperature=temperature)
        out_tokens.append(idx)
    words = [index_word.get(int(t), '[UNK]') for t in out_tokens]
    return ' '.join(words)


with st.spinner("Loading model and tokenizer..."):
    try:
        CFG, TOKENIZER, MODEL, INDEX_WORD = load_assets()
        st.success("Artifacts loaded.")
    except Exception as e:
        st.error(str(e))
        st.stop()

# Sidebar: metrics
st.sidebar.header("Metrics")
if EVAL_PATH.exists():
    with open(EVAL_PATH) as f:
        eval_metrics = json.load(f)
    st.sidebar.subheader("Evaluation (val)")
    for k, v in eval_metrics.items():
        st.sidebar.write(f"{k}: {v:.4f}")
else:
    st.sidebar.info("Run evaluation in the notebook to populate eval metrics.")

if COST_PATH.exists():
    with open(COST_PATH) as f:
        cost_metrics = json.load(f)
    st.sidebar.subheader("Cost metrics")
    for k, v in cost_metrics.items():
        if isinstance(v, (int, float)):
            st.sidebar.write(f"{k}: {v:.4f}")
        else:
            st.sidebar.write(f"{k}: {v}")

# Main UI
st.subheader("Try a prompt")
prompt = st.text_input("Prompt", value="the united states is")
col1, col2, col3 = st.columns([1,1,1])
with col1:
    num_words = st.number_input("Words to generate", min_value=1, max_value=50, value=10, step=1)
with col2:
    temperature = st.slider("Temperature", min_value=0.0, max_value=1.5, value=0.8, step=0.05)
with col3:
    greedy = st.checkbox("Greedy", value=False)

if st.button("Generate"):
    temp = 0.0 if greedy else float(temperature)
    completion = complete_text(MODEL, TOKENIZER, INDEX_WORD, CFG, prompt, num_words=num_words, temperature=temp)
    st.markdown("### Completion")
    st.write(completion)

st.caption("Model: next_word_lstm | Uses artifacts in ./models and ./artifacts generated by the notebook.")
